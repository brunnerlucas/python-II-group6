{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0415cc56-035e-4517-a132-c95feeff8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df902eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"enrich\"\n",
    "OUTPUT_FOLDER = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37650e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5380108 entries, 0 to 5380107\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   Date          5380108 non-null  object \n",
      " 1   Industry      5380108 non-null  object \n",
      " 2   Sector        5380108 non-null  object \n",
      " 3   Ticker        5380108 non-null  object \n",
      " 4   Open          5380108 non-null  float64\n",
      " 5   High          5380108 non-null  float64\n",
      " 6   Low           5380108 non-null  float64\n",
      " 7   Close         5380108 non-null  float64\n",
      " 8   Volume        5380108 non-null  int64  \n",
      " 9   Dividend      5380108 non-null  float64\n",
      " 10  Company Name  5380108 non-null  object \n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 451.5+ MB\n"
     ]
    }
   ],
   "source": [
    "key = \"us_shareproce_joined_companies\"\n",
    "\n",
    "share_prices = pd.read_csv(f\"data/{INPUT_FOLDER}/{key}.csv\")\n",
    "share_prices.info(show_counts=True)\n",
    "share_prices['Date'] = pd.to_datetime(share_prices['Date'])\n",
    "\n",
    "share_prices.set_index('Date', inplace=True)  # Set Date as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d48198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry        0\n",
       "Sector          0\n",
       "Ticker          0\n",
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividend        0\n",
       "Company Name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_prices.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d07655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-11</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.92</td>\n",
       "      <td>80.89</td>\n",
       "      <td>81.08</td>\n",
       "      <td>1071479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.43</td>\n",
       "      <td>82.06</td>\n",
       "      <td>80.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>1249295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-15</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.13</td>\n",
       "      <td>79.91</td>\n",
       "      <td>80.40</td>\n",
       "      <td>1627268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-16</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>80.82</td>\n",
       "      <td>80.96</td>\n",
       "      <td>77.19</td>\n",
       "      <td>77.55</td>\n",
       "      <td>3441597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-17</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>78.15</td>\n",
       "      <td>78.32</td>\n",
       "      <td>74.46</td>\n",
       "      <td>75.43</td>\n",
       "      <td>4471971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry      Sector Ticker   Open   High  \\\n",
       "Date                                                                          \n",
       "2019-04-11  Medical Diagnostics & Research  Healthcare      A  81.88  81.92   \n",
       "2019-04-12  Medical Diagnostics & Research  Healthcare      A  81.43  82.06   \n",
       "2019-04-15  Medical Diagnostics & Research  Healthcare      A  81.00  81.13   \n",
       "2019-04-16  Medical Diagnostics & Research  Healthcare      A  80.82  80.96   \n",
       "2019-04-17  Medical Diagnostics & Research  Healthcare      A  78.15  78.32   \n",
       "\n",
       "              Low  Close   Volume  Dividend              Company Name  \n",
       "Date                                                                   \n",
       "2019-04-11  80.89  81.08  1071479       0.0  AGILENT TECHNOLOGIES INC  \n",
       "2019-04-12  80.90  80.98  1249295       0.0  AGILENT TECHNOLOGIES INC  \n",
       "2019-04-15  79.91  80.40  1627268       0.0  AGILENT TECHNOLOGIES INC  \n",
       "2019-04-16  77.19  77.55  3441597       0.0  AGILENT TECHNOLOGIES INC  \n",
       "2019-04-17  74.46  75.43  4471971       0.0  AGILENT TECHNOLOGIES INC  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = share_prices[share_prices['Ticker'] == 'A']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc45fdf",
   "metadata": {},
   "source": [
    "Clasification model #1 (0 = down, 1 = up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ddb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/1mz19h4n1d920hbz6_952lk00000gn/T/ipykernel_45608/3227524502.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Change'] = df['Close'].diff().apply(lambda x: 1 if x > 0 else 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-11</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.92</td>\n",
       "      <td>80.89</td>\n",
       "      <td>81.08</td>\n",
       "      <td>1071479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.43</td>\n",
       "      <td>82.06</td>\n",
       "      <td>80.90</td>\n",
       "      <td>80.98</td>\n",
       "      <td>1249295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-15</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>81.00</td>\n",
       "      <td>81.13</td>\n",
       "      <td>79.91</td>\n",
       "      <td>80.40</td>\n",
       "      <td>1627268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-16</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>80.82</td>\n",
       "      <td>80.96</td>\n",
       "      <td>77.19</td>\n",
       "      <td>77.55</td>\n",
       "      <td>3441597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-17</th>\n",
       "      <td>Medical Diagnostics &amp; Research</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>A</td>\n",
       "      <td>78.15</td>\n",
       "      <td>78.32</td>\n",
       "      <td>74.46</td>\n",
       "      <td>75.43</td>\n",
       "      <td>4471971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AGILENT TECHNOLOGIES INC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Industry      Sector Ticker   Open   High  \\\n",
       "Date                                                                          \n",
       "2019-04-11  Medical Diagnostics & Research  Healthcare      A  81.88  81.92   \n",
       "2019-04-12  Medical Diagnostics & Research  Healthcare      A  81.43  82.06   \n",
       "2019-04-15  Medical Diagnostics & Research  Healthcare      A  81.00  81.13   \n",
       "2019-04-16  Medical Diagnostics & Research  Healthcare      A  80.82  80.96   \n",
       "2019-04-17  Medical Diagnostics & Research  Healthcare      A  78.15  78.32   \n",
       "\n",
       "              Low  Close   Volume  Dividend              Company Name  Change  \n",
       "Date                                                                           \n",
       "2019-04-11  80.89  81.08  1071479       0.0  AGILENT TECHNOLOGIES INC       0  \n",
       "2019-04-12  80.90  80.98  1249295       0.0  AGILENT TECHNOLOGIES INC       0  \n",
       "2019-04-15  79.91  80.40  1627268       0.0  AGILENT TECHNOLOGIES INC       0  \n",
       "2019-04-16  77.19  77.55  3441597       0.0  AGILENT TECHNOLOGIES INC       0  \n",
       "2019-04-17  74.46  75.43  4471971       0.0  AGILENT TECHNOLOGIES INC       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Change'] = df['Close'].diff().apply(lambda x: 1 if x > 0 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ba0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1019db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88bc27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def class_perc(data):\n",
    "    lendata = len(data)\n",
    "    classes = Counter(data)\n",
    "\n",
    "    for sclass, freq in classes.items():\n",
    "        perc = (freq / lendata) * 100\n",
    "        print(f\"Class '{sclass}': {perc:.2f}%\", \", freq:\",freq)\n",
    "\n",
    "class_perc(df['Change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b347934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_df(dataframe, seed=None, percentage=0.8):\n",
    "\n",
    "    X = df.loc[:, dataframe.columns != 'Change']\n",
    "    y = df['Change']\n",
    "\n",
    "    return train_test_split(X, y, test_size=1-percentage, random_state=seed, stratify=y) # note the stratify parameter\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_df(df, seed=42, percentage=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c51787",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data set: \", X_train.shape)\n",
    "print(\"Testing data set: \", X_test.shape)\n",
    "class_perc(Y_train.to_frame(name='Change')[\"Change\"])\n",
    "class_perc(Y_test.to_frame(name='Change')[\"Change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "shares_tree = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "shares_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d72459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, f1_score, accuracy_score, precision_recall_curve, confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pred_train = shares_tree.predict(X_train)\n",
    "print(\"Accuracy of training set = {0:.2%}\".format(accuracy_score(Y_train, pred_train)))\n",
    "\n",
    "pred_test = shares_tree.predict(X_test)\n",
    "print(\"Accuracy of testing set = {0:.2%}\".format(accuracy_score(Y_test, pred_test)))\n",
    "\n",
    "#Very high overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_tree(tree, feature_names):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data, feature_names=feature_names,\n",
    "                    filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_png(\"titanic_train.png\")\n",
    "    return Image(graph.create_png())\n",
    "\n",
    "plot_tree(shares_tree, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node=shares_tree.tree_\n",
    "node=0\n",
    "print(\"Samples: \", root_node.n_node_samples[node])\n",
    "print(\"Proportions per class: \",root_node.value[node])\n",
    "print(\"Samples per class: \", root_node.value[node]*root_node.n_node_samples[node])\n",
    "print(\"Impurity: {0:.2%}\".format(root_node.impurity[node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes: \", shares_tree.tree_.node_count)\n",
    "print(\"Number of leaves: \", shares_tree.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "importances = shares_tree.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.bar(X_train.columns[indices], importances[indices]) #average reduction in impurity resulting from splitting at each node of the tree using that feature\n",
    "plt.title('Feature Importance', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d25d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': range(1,9)} # 9 different depth levels\n",
    "\n",
    "shares_tree_pruned_cv = GridSearchCV(shares_tree,\n",
    "                   param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5 , n_jobs=1, verbose=1)\n",
    "\n",
    "shares_tree_pruned_cv.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(shares_tree_pruned_cv.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = shares_tree_pruned_cv.cv_results_['mean_test_score']\n",
    "stds = shares_tree_pruned_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, shares_tree_pruned_cv.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.errorbar(range(1,9,1), [m for m in means], yerr=stds, fmt='--o')\n",
    "plt.title('Accuracy for different Depths', fontsize=20)\n",
    "plt.xlabel(\"Depth\", fontsize=16)\n",
    "plt.ylabel(\"Accuracy\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab37384",
   "metadata": {},
   "outputs": [],
   "source": [
    "shares_tree_pruned = DecisionTreeClassifier(random_state=42, max_depth=5, class_weight='balanced')\n",
    "tree = shares_tree_pruned.fit(X_train, Y_train)\n",
    "\n",
    "probabilities = shares_tree_pruned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.5\n",
    "predictions_test = (probabilities >= threshold).astype(int)\n",
    "\n",
    "print(\"Accuracy = {0:.2%}\".format(accuracy_score(Y_test, predictions_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "prob_pred = tree.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.0, 1.0, step=0.1)\n",
    "recall_scores = [metrics.recall_score(Y_test, prob_pred > t, average='macro') for t in thresholds]\n",
    "precis_scores = [metrics.precision_score(Y_test, prob_pred > t, average='macro') for t in thresholds]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thresholds, recall_scores, label=\"Recall @ t\")\n",
    "ax.plot(thresholds, precis_scores, label=\"Precision @ t\")\n",
    "ax.axvline(0.5, c=\"gray\", linestyle=\"--\", label=\"Default Threshold\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Metric @ Threshold\")\n",
    "ax.set_box_aspect(1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c63317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes: \", shares_tree_pruned.tree_.node_count)\n",
    "print(\"Number of leaves: \", shares_tree_pruned.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "text_representation = tree.export_text(shares_tree_pruned, feature_names=list(X_test.columns))\n",
    "print(text_representation)\n",
    "\n",
    "# optionally, we can export them to a text file\n",
    "with open(\"shares_pruned.log\", \"w\") as fout:\n",
    "    fout.write(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca044923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(shares_tree_pruned, out_file=None,\n",
    "                                class_names=[\"No\",\"Yes\"],\n",
    "                                feature_names=X_train.columns,\n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95322384",
   "metadata": {},
   "source": [
    "Bagging (1 up, -1 down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.iloc[:,df.columns != 'Change'],\n",
    "                                                    df['Change'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee22635",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \", x_train.shape)\n",
    "print(\"Test: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "baseRF = RandomForestClassifier(n_estimators = 200,  # The number of trees in the forest\n",
    "                               random_state = 42, # This parameter allows to replicate results\n",
    "                               n_jobs = -1, # The number of jobs to run in parallel (-1 means all processors, 1 no parallelism)\n",
    "                               oob_score = True,\n",
    "                               class_weight='balanced') # Whether to use out-of-bag samples to estimate the generalization score (increases time)\n",
    "\n",
    "# The OOB score is an estimate of the generalization error of the model, calculated with the data not used to train it.\n",
    "# Since each tree is trained on a bootstrapped sample, they all use approximately 2/3 of the data (this is a mathematical consequence\n",
    "# of random sampling with replacement). Therefore, for each of the learners we have 1/3 of the dataset as Out Of Bag (OOB) observations\n",
    "# which can be used to test the model and estimate its generalisation error. By averaging these OOB error estimates across the trees,\n",
    "# RF produces a robust error estimate for the ensemble during training time at almost no additional computational cost.\n",
    "\n",
    "# other parameters:\n",
    "# criterion{\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
    "# max_depth: int, default=None\n",
    "# min_samples_leaf: int or float, default=1 - The minimum number of samples required to be at a leaf node\n",
    "# min_samples_split: int or float, default=2 - The minimum number of samples required to split an internal node:\n",
    "# max_features{\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\" - The number of features to consider when looking for the best split\n",
    "\n",
    "baseRF.fit(x_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_test = baseRF.predict(x_test)\n",
    "\n",
    "print(\"OOB score: {:.2%}\".format(baseRF.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf' :[10,15,20],\n",
    "    'max_features' : [4,6,8],\n",
    "    'criterion' : ['gini','entropy'] #,'log_loss']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3775190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cvRF = GridSearchCV(estimator=baseRF, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "#cv is the number of cross validation iterations to be performed\n",
    "cvRF.fit(x_train,y_train)\n",
    "\n",
    "print (\"Completed in {:0.0f} seconds \".format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = cvRF.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC: \", '{0:0.2%}'.format(cvRF.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cvRF = GridSearchCV(estimator=baseRF, param_grid=param_grid, cv=5, scoring='roc_auc')\n",
    "#cv is the number of cross validation iterations to be performed\n",
    "cvRF.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657128e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC: \", '{0:0.2%}'.format(cvRF.best_score_))\n",
    "\n",
    "#Again showing very high overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31757047",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cvRF.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e203e",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f362bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = RandomForestClassifier(n_estimators = 200,\n",
    "                               random_state = 0,\n",
    "                               max_features = 6, #this parameter makes the difference between simple Bagging and Random Forests\n",
    "                               n_jobs = -1,\n",
    "                               oob_score = True,\n",
    "                               # criterion = 'entropy',\n",
    "                               min_samples_leaf = 10)\n",
    "model_RF.fit(x_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_test = model_RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb377a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OOB score: {:.2%}\".format(model_RF.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dec2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_recall_curve, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "pred_prob = model_RF.predict_proba(x_test) \n",
    "prob_malign = [p[1] for p in pred_prob] \n",
    "auc = roc_auc_score(y_test, prob_malign)\n",
    "print(\"ROC AUC score: {:.2%}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, prob_malign, pos_label=1)\n",
    "\n",
    "train_acc = round(model_RF.score(x_train,y_train) * 100,2) \n",
    "test_acc = round(model_RF.score(x_test,y_test) * 100,2) \n",
    "print(\"Train Accuracy score: \", train_acc, \"%\")\n",
    "print(\"Test Accuracy score: \", test_acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_RF.feature_importances_\n",
    "\n",
    "indexes = np.argsort(importances)[::-1]\n",
    "sorted_imp = importances[indexes]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(importances)), importances[indexes], align='center')\n",
    "plt.xticks(range(len(importances)), np.array(model_RF.feature_names_in_)[indexes], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.title(\"Relative feature importances (from 0 to 1)\")\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "             f'{sorted_imp[i]:.2f}', ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n",
    "#Dividend is not important at all for the analysis - can be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "cv_scores    = []\n",
    "\n",
    "estimator_range = range(100, 300, 25) #from 5 trees to 50, step 5\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "    model_RF = RandomForestClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                max_features = 5, # the previous optimum\n",
    "                oob_score    = False,\n",
    "                n_jobs       = -1,\n",
    "                random_state = 100,\n",
    "                class_weight='balanced'\n",
    "             )\n",
    "\n",
    "    model_RF.fit(x_train, y_train)\n",
    "    predictions = model_RF.predict(x_test)\n",
    "    acc=accuracy_score(y_test, predictions)\n",
    "    print(\"% Accuracy of test dataset for {} trees is {:.3f}\".format(n_estimators, acc))\n",
    "    train_scores.append(acc) # storing accuracy from each iteration\n",
    "\n",
    "    # and we also store the accuracy mean obtained from running a 5-fold validation\n",
    "    cvscores = cross_val_score(\n",
    "                estimator = model_RF,\n",
    "                X         = x_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'accuracy',\n",
    "                cv        = 5\n",
    "             )\n",
    "    cv_scores.append(cvscores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(estimator_range, train_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title('Accuracy of Test Dataset vs. Number of Trees')\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(estimator_range)  # Para mostrar todos los valores en el eje x\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "ax.plot(estimator_range, cv_scores, label=\"cv scores\")\n",
    "ax.plot(estimator_range[np.argmax(cv_scores)], max(cv_scores),\n",
    "        marker='o', color = \"red\", label=\"max score\")\n",
    "ax.set_ylim(0.65, 0.70)\n",
    "ax.set_ylabel(\"% Accuracy\")\n",
    "ax.set_xlabel(\"n_estimators\")\n",
    "ax.set_title(\"Evolution of cv-error vs. number of trees\")\n",
    "plt.legend();\n",
    "print(f\"Optimum number of trees: {estimator_range[np.argmax(cv_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100823f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF = RandomForestClassifier(n_estimators = 200,\n",
    "                               random_state = 100,\n",
    "                               max_features = 6, #this parameter makes the difference between simple Bagging and Random Forests\n",
    "                               n_jobs = -1,\n",
    "                               oob_score = True,\n",
    "                               # criterion = 'entropy',\n",
    "                               min_samples_leaf = 10,\n",
    "                               class_weight='balanced')\n",
    "model_RF.fit(x_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_test = model_RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa99a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OOB score: {:.2%}\".format(model_RF.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, prob_malign, pos_label=1)\n",
    "\n",
    "train_acc = round(model_RF.score(x_train,y_train) * 100,2) #Train Accuracy score\n",
    "test_acc = round(model_RF.score(x_test,y_test) * 100,2) #Test Accuracy score\n",
    "print(\"Train Accuracy score: \", train_acc, \"%\")\n",
    "print(\"Test Accuracy score: \", test_acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cb04b",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26676450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np             # Data manipulation\n",
    "from matplotlib import pyplot as plt         # Graphing\n",
    "import seaborn as sns                        # Graphing\n",
    "\n",
    "import statsmodels.api as sm                    # Statistical analysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats                      # Stats\n",
    "\n",
    "#sns.set(style=\"white\")                       # Tuning the style of charts\n",
    "import warnings                              # Disable some warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model, df_reserved = train_test_split(df, test_size=0.1, random_state=42)\n",
    "print (\"Sample size dataset reserved for prediction: \", df_reserved.shape[0], \"records\")\n",
    "\n",
    "target = 'Change'\n",
    "\n",
    "y = df_model[target]\n",
    "\n",
    "# cross validation (80%-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size=0.2)\n",
    "print (\"Sample size train dataset: \", X_train.shape)\n",
    "print (\"Sample size test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise function\n",
    "def stepwise_selection(X, y,\n",
    "                       initial_list=[],\n",
    "                       threshold_in=0.05,\n",
    "                       threshold_out = 0.1,\n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection\n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features\n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95420be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stepwise_selection(X_train, y_train)     #For logit regression, stepwise does an iterative process\n",
    "print('resulting features:')\n",
    "print(result) # relevant variables\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e60eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.1)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(X_train_stepwise.corr(), annot=True, fmt=\".2f\", linewidths=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72514a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
